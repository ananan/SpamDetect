# 实验报告

*施韶韵 计34 2013011358*

## 实验目的

在垃圾邮件识别问题上，改进朴素贝叶斯分类器。

## 实验原理

记某个文档 $d = (t_1, t_2, ..., t_k)$，其中$t_i$为文档中的单词  
则某个文档$d$属于类$c$的概率为
$$P(c|t_1t_2...t_k) = \frac{P(t_1t_2...t_k|c)P( c )}{P(t_1t_2...t_k)}$$
假设单词出现概率相互独立，则
$$P(c|t_1t_2...t_k) = \frac{P(t_1|c)P(t_2|c)...P(t_k|c)P( c )}{P(t_1t_2...t_k)}$$
则对于文档$d$在类别集合$C$中的分类为
$$max\ P(c|t_1t_2...t_k), c\in C$$

## 实验内容

### 基本框架

- 伯努利模型
$$ P( c ) = \frac{类c下文件总数}{整个训练样本的文件总数} $$
$$ P(t_i|c) =\frac{类c下包含单词t_i的文件数+1}{c下的文件总数+2}$$
> 其中平滑的添加实际意义是向每个类别中新增了两个文件：空文件；包含所有单词各一个的文件。

- 多项式模型
$$ P( c ) = \frac{类c下单词总数}{整个训练样本的单词总数}$$
$$ P(t_i|c) = \frac{类c下单词t_i在各个文档中出现过的次数之和+1}{类c下单词总数+训练集中不同单词的个数}$$
> 其中平滑添加的实际意义是向每个类别中新增一个文件，包含所有训练集单词各一个。

- 框架对比

    > 取1000个数据，其中随机抽取一半作为训练集，另一半作为测试集
    
    伯努利模型：accuracy 0.836，precision 0.997005988024，recall 0.804347826087  
    多项式模型：accuracy 0.976，precision 0.983173076923，recall 0.987922705314 
    
    > 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集
    
    伯努利模型：accuracy 0.944，precision 0.970954356846，recall 0.947368421053      
    多项式模型：accuracy 0.9396，precision 0.952927669346，recall 0.96009253904   
    
    伯努利模型中不考虑文档中单词出现的频率，使得文档特征中各个单词的权重一样，可能丢失分类信息。而多项式模型考虑了词频，每次出现都计算概率，但是这有可能使得某个主题词的权重过高而误导分类。因为对于一个在文档中出现多次的词来说，它的每次出现并不能认为是独立的，出现一次的词很可能出现第二次第三次。    
    从实验结果来看，训练数据较少时，似乎是多项式模型表现较好，可能因为此时以文档为粒度计算的伯努利模型得不到足够准确的$P(t_i|c)$。但是伯努利的precision很高，且在训练集大小提升到5000时已明显优于多项式模型。垃圾邮件分类中，我们更希望precision足够高因为我们不希望一个正常邮件被分类到垃圾邮件而导致正常交流遇到问题。  
    另外，伯努利模型每次预测考虑的单词集合是确定的，并不依赖于预测文档，只不过文档中没有出现的单词是计算反概率。因此，它更适合做特征提取，扩展性更好。  
    因此，伯努利模型更适合垃圾邮件识别。

### Stopwords去除

中文stopwords列表取自百度Guide：http://www.baiduguide.com/baidu-stopwords/

> 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集

伯努利模型：accuracy 0.9492，precision 0.981120584653，recall 0.943760984183  
多项式模型：accuracy 0.9548，precision 0.963911525029，recall 0.970123022847   

可见stopwords的确是一些无用信息，将它们从文档特征中去除后，不但没有影响分类器的准确性，还对性能有略微的提升。

### 特征提取


