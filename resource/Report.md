# 实验报告

*施韶韵 计34 2013011358*

## 实验目的

在垃圾邮件识别问题上，改进朴素贝叶斯分类器。

## 实验原理

记某个文档 $d = (t_1, t_2, ..., t_k)$，其中$t_i$为文档中的单词  
则某个文档$d$属于类$c$的概率为
$$P(c|t_1t_2...t_k) = \frac{P(t_1t_2...t_k|c)P( c )}{P(t_1t_2...t_k)}$$
假设单词出现概率相互独立，则
$$P(c|t_1t_2...t_k) = \frac{P(t_1|c)P(t_2|c)...P(t_k|c)P( c )}{P(t_1t_2...t_k)}$$
则对于文档$d$在类别集合$C$中的分类为
$$max\ P(c|t_1t_2...t_k), c\in C$$

## 实验内容

### 基本框架

- 伯努利模型
$$ P( c ) = \frac{类c下文件总数}{整个训练样本的文件总数} $$
$$ P(t_i|c) =\frac{类c下包含单词t_i的文件数+1}{c下的文件总数+2}$$
> 其中平滑的添加实际意义是向每个类别中新增了两个文件：空文件；包含所有单词各一个的文件。

- 多项式模型
$$ P( c ) = \frac{类c下单词总数}{整个训练样本的单词总数}$$
$$ P(t_i|c) = \frac{类c下单词t_i在各个文档中出现过的次数之和+1}{类c下单词总数+训练集中不同单词的个数}$$
> 其中平滑添加的实际意义是向每个类别中新增一个文件，包含所有训练集单词各一个。

- 框架对比

    > 取1000个数据，其中随机抽取一半作为训练集，另一半作为测试集
    
    伯努利模型：accuracy 0.836，precision 0.997005988024，recall 0.804347826087  
    多项式模型：accuracy 0.976，precision 0.983173076923，recall 0.987922705314 
    
    > 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集
    
    伯努利模型：accuracy 0.944，precision 0.970954356846，recall 0.947368421053      
    多项式模型：accuracy 0.9396，precision 0.952927669346，recall 0.96009253904   
    
    伯努利模型中不考虑文档中单词出现的频率，使得文档特征中各个单词的权重一样，可能丢失分类信息。而多项式模型考虑了词频，每次出现都计算概率，但是这有可能使得某个主题词的权重过高而误导分类。因为对于一个在文档中出现多次的词来说，它的每次出现并不能认为是独立的，出现一次的词很可能出现第二次第三次。    
    从实验结果来看，训练数据较少时，似乎是多项式模型表现较好，可能因为此时以文档为粒度计算的伯努利模型得不到足够准确的$P(t_i|c)$。但是伯努利的precision很高，且在训练集大小提升到5000时已明显优于多项式模型。垃圾邮件分类中，我们更希望precision足够高因为我们不希望一个正常邮件被分类到垃圾邮件而导致正常交流遇到问题。  
    另外，伯努利模型每次预测考虑的单词集合是确定的，并不取决于预测文档，只不过文档中没有出现的单词是计算反概率。因此，它更适合做特征提取，扩展性更好。  
    因此，伯努利模型更适合垃圾邮件识别。

### Stopwords去除

中文stopwords列表取自百度Guide：http://www.baiduguide.com/baidu-stopwords/  
在分词后的单词信息统计时，跳过所有的Stopwords。

> 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集

伯努利模型：accuracy 0.9492，precision 0.981120584653，recall 0.943760984183  
多项式模型：accuracy 0.9548，precision 0.963911525029，recall 0.970123022847   

可见stopwords的确是一些无用信息，将它们从文档特征中去除后，不但没有影响分类器的准确性，还对性能有略微的提升。

### 特征提取

应用于伯努利模型

- 时间对比

> 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集

不做特征提取：
accuracy 0.958 ，precision 0.969470046083，recall 0.970028818444，time 182.083952904  
自定义算法提取10个特征：
accuracy 0.8944 ，precision 0.935981031417，recall 0.910086455331，time 0.83980512619

可见，不做特征提取时一个邮件的维度过大，算法执行时间是无法容忍的，特征下降到十个之后虽然算法的准确程度有明显下降，但是执行时间进入了一个能够接受的范围。

- 特征提取算法

> 取5000个数据，其中随机抽取一半作为训练集，另一半作为测试集，特征提取数为10

期望交叉熵：accuracy 0.8028 ，precision 0.780939476061，recall 0.995394358089  
信息增益：accuracy 0.7248 ，precision 0.945624468989，recall 0.640759930915  
互信息：accuracy 0.8968 ，precision 0.930191972077，recall 0.920552677029  
自定义：accuracy 0.8804 ，precision 0.931572629052，recall 0.8934945308  

其中，自定义特征提取算法是考虑到伯努利贝叶斯模型的算法特征，取$|P(t_i|c=0)-P(t_i|c=1)|$为评价标准。可见期望互信息和自定义的特征提取算法表现较好，而信息增益的算法对precision有利，期望交叉熵则表现很差。  
于是我希望综合这除期望交叉熵之外的三个特征提取算法，对于三个特征提取算法先给出三个长度大于要提取特征数目的序列$(f_1,f_2...f_n)$，每个特征的权重随序号递减，且保证在多个序列中同时出现的比在较少序列中出现的权重和要大，$3*weight(f_n)>2*weight(f_1)$。对所有在三个序列中出现的特征，求其权重和，按从大到小排序后取符合数目的特征。  

综合：accuracy 0.8544 ，precision 0.957859531773，recall 0.826312752452

可见，这种综合算法是可以提高precision的，但是recall相比互信息算法下降到了0.83。

- 特征数目

- 特征独立性

